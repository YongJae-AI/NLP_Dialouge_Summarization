{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialogue Summarization EDA\n",
    "\n",
    "이 노트북은 대회용 `train/dev/test` 대화 요약 데이터를 탐색하고,\n",
    "모델링/전처리/프롬프트 설계를 위한 인사이트를 얻기 위한 EDA 계획 및 실행을 담습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA 전체 계획\n",
    "\n",
    "1. **데이터 구조 파악**  \n",
    "   - `train/dev/test` 행 개수, 컬럼(`fname, dialogue, summary, topic`) 구조 확인  \n",
    "   - topic 분포 (train/dev) 비교, test에 topic 유무 확인\n",
    "\n",
    "2. **대화/요약 길이 통계**  \n",
    "   - 문자/토큰 기준 길이 분포 (평균, 중앙값, 상/하위 quantile)  \n",
    "   - encoder_max_len=1024, decoder_max_len=80 기준으로 잘리는 비율 추정  \n",
    "   - 발화(turn) 개수 분포 (#Person1/#Person2 등장 회수)\n",
    "\n",
    "3. **토픽/스타일 분석**  \n",
    "   - topic별 평균 대화 길이 / 요약 길이 비교  \n",
    "   - 대표적인 대화-요약 페어 몇 개 샘플링해서, 요약 스타일(존댓말/반말, 요약의 추상화/추출 비율) 파악  \n",
    "   - 요약에서 자주 등장하는 키워드/표현 조사 (간단한 빈도/WordCloud 수준)\n",
    "\n",
    "4. **train/dev 데이터 분포 차이 체크**  \n",
    "   - 길이 분포, topic 분포, 자주 등장하는 단어 등 비교  \n",
    "   - 분포가 비슷한지, dev가 특정 topic에 편향되어 있는지 확인\n",
    "\n",
    "5. **모델/프롬프트 설계에 직접 연결되는 분석**  \n",
    "   - 긴 대화에서 앞/뒤 어느 부분이 요약에 더 많이 반영되는지 (간단한 n-gram overlap 위치 분석)  \n",
    "   - 스타일 프롬프트 후보 문구를 몇 개 정의하고, 요약 스타일과 매칭되는지 눈으로 검증  \n",
    "   - KoBART/T5 토크나이저 기준 토큰 길이 분포 (추후 필요 시)\n",
    "\n",
    "6. **제출 파일/파이프라인 sanity check**  \n",
    "   - `prediction/*.csv`에서 `fname` 정렬/중복 여부, summary 공백/길이 확인  \n",
    "   - 극단적으로 짧거나 긴 요약 몇 개 샘플링하여 품질/스타일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩 셀입니다.\n",
    "# - data/train.csv, data/dev.csv, data/test.csv가 존재하는지 먼저 확인하고,\n",
    "#   없으면 친절한 에러 메시지를 출력합니다.\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "DEV_PATH = DATA_DIR / \"dev.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test.csv\"\n",
    "\n",
    "missing = [p for p in [TRAIN_PATH, DEV_PATH, TEST_PATH] if not p.exists()]\n",
    "if missing:\n",
    "    missing_str = \", \".join(str(p) for p in missing)\n",
    "    raise FileNotFoundError(\n",
    "        f\"다음 파일을 찾을 수 없습니다: {missing_str}\\n\"\n",
    "        \"- data 디렉토리에 대회 데이터를 다시 풀어 넣은 뒤 이 셀을 다시 실행하세요.\"\n",
    "    )\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "dev_df = pd.read_csv(DEV_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "train_df.head(), dev_df.head(), test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 구조 및 기본 통계\n",
    "\n",
    "- 각 split의 행 개수, 컬럼, 결측치, topic 유무 등 기본 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Dev shape:\", dev_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "print(\"\\nTrain columns:\", train_df.columns.tolist())\n",
    "print(\"Dev columns:\", dev_df.columns.tolist())\n",
    "print(\"Test columns:\", test_df.columns.tolist())\n",
    "\n",
    "print(\"\\nTrain topic value_counts:\\n\", train_df.get(\"topic\", pd.Series()).value_counts().head())\n",
    "print(\"\\nDev topic value_counts:\\n\", dev_df.get(\"topic\", pd.Series()).value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 길이 분포 분석 (문자 기준)\n",
    "\n",
    "- dialogue 길이, summary 길이의 기본 통계를 보고, encoder/decoder max length 설정이 적절한지 감각을 잡습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name, df in [(\"train\", train_df), (\"dev\", dev_df)]:\n",
    "    df[\"dialogue_len_char\"] = df[\"dialogue\"].astype(str).str.len()\n",
    "    df[\"summary_len_char\"] = df.get(\"summary\", \"\").astype(str).str.len()\n",
    "\n",
    "    print(f\"==== {split_name.upper()} ====\")\n",
    "    print(\"dialogue_len_char describe:\\n\", df[\"dialogue_len_char\"].describe())\n",
    "    print(\"summary_len_char describe:\\n\", df[\"summary_len_char\"].describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 발화(turn) 수 분포\n",
    "\n",
    "- `#Person1#`, `#Person2#` 패턴을 이용해 대화 turn 수 분포를 대략적으로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_turns(text: str) -> int:\n",
    "    return len(re.findall(r\"#Person[0-9]+#\", str(text)))\n",
    "\n",
    "train_df[\"num_turns\"] = train_df[\"dialogue\"].apply(count_turns)\n",
    "dev_df[\"num_turns\"] = dev_df[\"dialogue\"].apply(count_turns)\n",
    "\n",
    "print(\"Train num_turns describe:\\n\", train_df[\"num_turns\"].describe())\n",
    "print(\"Dev num_turns describe:\\n\", dev_df[\"num_turns\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. topic별 길이/스타일 차이 (추후 확장)\n",
    "\n",
    "- topic이 존재한다면, topic별로 길이/turn 수/요약 길이 차이를 비교합니다.\n",
    "- 필요 시 시각화(히스토그램, 박스플롯)를 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"topic\" in train_df.columns:\n",
    "    topic_stats = train_df.groupby(\"topic\")[\"dialogue_len_char\", \"summary_len_char\", \"num_turns\"].describe()\n",
    "    topic_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 샘플 대화-요약 페어 확인\n",
    "\n",
    "- 무작위로 몇 개를 뽑아서, 요약 스타일과 프롬프트 설계 방향을 눈으로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_N = 3\n",
    "sample_rows = train_df.sample(SAMPLE_N, random_state=42)\n",
    "for i, row in sample_rows.iterrows():\n",
    "    print(\"==== SAMPLE ====\\n\")\n",
    "    print(\"fname:\", row.get(\"fname\"))\n",
    "    print(\"topic:\", row.get(\"topic\"))\n",
    "    print(\"[DIALOGUE]\\n\", row[\"dialogue\"][:1000])\n",
    "    print(\"\\n[SUMMARY]\\n\", row[\"summary\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. KoBART 토크나이저 기준 토큰 길이 분포\n",
    "\n",
    "- 이 셀에서는 **KoBART 토크나이저**로 대화문을 토크나이즈했을 때 토큰 길이 분포를 봅니다.\n",
    "- encoder_max_len=1024 설정이 얼마나 여유 있는지, 잘리는 샘플 비율이 어느 정도인지 확인하는 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBART 토크나이저를 불러와서, 대화문의 토큰 길이 분포를 확인하는 셀입니다.\n",
    "# - encoder_max_len=1024 설정으로 충분한지 확인하기 위함입니다.\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "kobart_tok = PreTrainedTokenizerFast.from_pretrained(\"gogamza/kobart-base-v1\")\n",
    "\n",
    "def token_len(text: str) -> int:\n",
    "    return len(kobart_tok.encode(str(text), add_special_tokens=True))\n",
    "\n",
    "train_df[\"dialogue_len_tok\"] = train_df[\"dialogue\"].apply(token_len)\n",
    "dev_df[\"dialogue_len_tok\"] = dev_df[\"dialogue\"].apply(token_len)\n",
    "\n",
    "print(\"[TRAIN] dialogue_len_tok describe:\\n\", train_df[\"dialogue_len_tok\"].describe())\n",
    "print(\"[DEV] dialogue_len_tok describe:\\n\", dev_df[\"dialogue_len_tok\"].describe())\n",
    "print(\"\\n[TRAIN] encoder_max_len=1024 초과 비율:\", (train_df[\"dialogue_len_tok\"] > 1024).mean())\n",
    "print(\"[DEV] encoder_max_len=1024 초과 비율:\", (dev_df[\"dialogue_len_tok\"] > 1024).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 요약 길이 vs 대화 길이 상관 관계\n",
    "\n",
    "- 이 셀에서는 **대화 길이(문자 기준)**와 **요약 길이(문자 기준)**의 상관 관계를 계산합니다.\n",
    "- \"대화가 길어질수록 요약도 길어지는지\" 대략적인 경향을 보는 것이 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 길이(문자)와 요약 길이(문자)의 상관 관계를 계산하는 셀입니다.\n",
    "# - scatter plot까지는 아니지만, 상관 계수로 대략적인 경향을 봅니다.\n",
    "corr = train_df[[\"dialogue_len_char\", \"summary_len_char\"]].corr()\n",
    "print(\"[TRAIN] dialogue_len_char vs summary_len_char 상관 계수:\\n\", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 요약 스타일 키워드 빈도\n",
    "\n",
    "- 이 셀에서는 요약문에서 자주 등장하는 단어를 세어 봅니다.\n",
    "- \"환자\", \"고객\", \"상담\", \"예약\" 등 어떤 표현이 많이 나오는지 보고,\n",
    "  요약 스타일(예: 의료/상담/일상 대화 비율)을 감각적으로 파악하는 것이 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약문에서 자주 등장하는 단어의 빈도를 간단히 계산하는 셀입니다.\n",
    "# - 형태소 분석까지는 하지 않고, 한글/영문/숫자 토큰 기준으로 rough하게 봅니다.\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenize_korean(text: str):\n",
    "    return re.findall(r\"[가-힣A-Za-z0-9]+\", str(text))\n",
    "\n",
    "words = []\n",
    "sample_summaries = train_df[\"summary\"].dropna().sample(min(1000, len(train_df)), random_state=42)\n",
    "for s in sample_summaries:\n",
    "    words.extend(tokenize_korean(s))\n",
    "\n",
    "counter = Counter(words)\n",
    "print(\"[요약문 상위 50개 토큰 빈도]\")\n",
    "for w, c in counter.most_common(50):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. train vs dev 길이 분포 비교\n",
    "\n",
    "- 이 셀에서는 train/dev 간에 **대화 길이/요약 길이 평균**이 얼마나 다른지 비교합니다.\n",
    "- train과 dev 분포가 크게 다르면, dev 성능이 실제 test 분포와도 다를 수 있으므로,\n",
    "  분포 차이를 확인하는 것이 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 dev의 길이 분포(평균 기준)를 비교하는 셀입니다.\n",
    "print(\"[TRAIN] dialogue_len_char mean:\", train_df[\"dialogue_len_char\"].mean())\n",
    "print(\"[DEV]   dialogue_len_char mean:\", dev_df[\"dialogue_len_char\"].mean())\n",
    "print(\"[TRAIN] summary_len_char mean:\", train_df[\"summary_len_char\"].mean())\n",
    "print(\"[DEV]   summary_len_char mean:\", dev_df[\"summary_len_char\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. prediction sanity check\n",
    "\n",
    "- 이 셀에서는 현재까지 생성한 **제출용 CSV**를 간단히 검증합니다.\n",
    "- 예: `fname` 중복 여부, summary가 비어 있는지, 길이 분포가 너무 극단적이지 않은지 확인합니다.\n",
    "- 아래 파일명은 예시이며, 실제로 확인하고 싶은 최신 CSV 경로로 수정해서 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 prediction CSV가 기본 형식을 잘 따르는지 확인하는 셀입니다.\n",
    "# - fname 중복/누락, summary 공백 비율, 요약 길이 분포 등을 간단히 체크합니다.\n",
    "\n",
    "PRED_PATH = \"prediction/2511292249_kobart-base-style_prompt_bs8.csv\"  # 필요에 따라 최신 파일로 변경\n",
    "\n",
    "try:\n",
    "    pred_df = pd.read_csv(PRED_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다: {PRED_PATH}\")\n",
    "else:\n",
    "    print(pred_df.head())\n",
    "    print(\"rows:\", len(pred_df))\n",
    "    print(\"fname unique:\", pred_df[\"fname\"].nunique())\n",
    "    empty_ratio = (pred_df[\"summary\"].astype(str).str.strip() == \"\").mean()\n",
    "    print(\"empty summary 비율:\", empty_ratio)\n",
    "    print(\"summary 길이 통계:\\n\", pred_df[\"summary\"].astype(str).str.len().describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
