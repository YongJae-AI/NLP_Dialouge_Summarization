model:
  name: beomi/gemma-ko-2b

data:
  train_path: /root/NLP_Dialouge_Summarization/data/data/train.csv
  dev_path: /root/NLP_Dialouge_Summarization/data/data/dev.csv
  encoder_max_len: 896
  decoder_max_len: 80
  chunk_overlap: true
  chunk_overlap_tokens: 128

style_prompt: "질문: 아래 한국어 대화의 핵심 내용을 간결한 요약으로 정리하시오. 화자·대상 이름/역할을 절대 바꾸지 말고, 화자 발언을 다른 사람에게 돌리지 말 것. 행동 주체/대상을 그대로 유지하라. 지금 하는 일과 앞으로 할 계획을 구분해서 서술하라. 문장은 가능하면 2문장 이내, 필요 시 3문장까지 자연스럽게 이어지는 서술문으로, 대화 진행 순서(사건 발생 순서)에 맞게 간결하게 적어라. 답변:"

train:
  learning_rate: 0.00015
  num_train_epochs: 4
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  warmup_ratio: 0.03
  weight_decay: 0.1
  lora_r: 64
  lora_alpha: 128
  lora_dropout: 0.05
  save_steps: 500
  eval_steps: 500
  logging_steps: 50
  bf16: true
  max_steps: null
  early_stopping_patience: 4

paths:
  checkpoint_dir: /root/NLP_Dialouge_Summarization/checkpoints/gemma-ko-qlora
