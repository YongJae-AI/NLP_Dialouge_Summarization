{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialogue Summarization EDA\n",
    "\n",
    "이 노트북은 대회용 `train/dev/test` 대화 요약 데이터를 탐색하고,\n",
    "모델링/전처리/프롬프트 설계를 위한 인사이트를 얻기 위한 EDA 계획 및 실행을 담습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA 전체 계획\n",
    "\n",
    "1. **데이터 구조 파악**  \n",
    "   - `train/dev/test` 행 개수, 컬럼(`fname, dialogue, summary, topic`) 구조 확인  \n",
    "   - topic 분포 (train/dev) 비교, test에 topic 유무 확인\n",
    "\n",
    "2. **대화/요약 길이 통계**  \n",
    "   - 문자/토큰 기준 길이 분포 (평균, 중앙값, 상/하위 quantile)  \n",
    "   - encoder_max_len=1024, decoder_max_len=80 기준으로 잘리는 비율 추정  \n",
    "   - 발화(turn) 개수 분포 (#Person1/#Person2 등장 회수)\n",
    "\n",
    "3. **토픽/스타일 분석**  \n",
    "   - topic별 평균 대화 길이 / 요약 길이 비교  \n",
    "   - 대표적인 대화-요약 페어 몇 개 샘플링해서, 요약 스타일(존댓말/반말, 요약의 추상화/추출 비율) 파악  \n",
    "   - 요약에서 자주 등장하는 키워드/표현 조사 (간단한 빈도/WordCloud 수준)\n",
    "\n",
    "4. **train/dev 데이터 분포 차이 체크**  \n",
    "   - 길이 분포, topic 분포, 자주 등장하는 단어 등 비교  \n",
    "   - 분포가 비슷한지, dev가 특정 topic에 편향되어 있는지 확인\n",
    "\n",
    "5. **모델/프롬프트 설계에 직접 연결되는 분석**  \n",
    "   - 긴 대화에서 앞/뒤 어느 부분이 요약에 더 많이 반영되는지 (간단한 n-gram overlap 위치 분석)  \n",
    "   - 스타일 프롬프트 후보 문구를 몇 개 정의하고, 요약 스타일과 매칭되는지 눈으로 검증  \n",
    "   - KoBART/T5 토크나이저 기준 토큰 길이 분포 (추후 필요 시)\n",
    "\n",
    "6. **제출 파일/파이프라인 sanity check**  \n",
    "   - `prediction/*.csv`에서 `fname` 정렬/중복 여부, summary 공백/길이 확인  \n",
    "   - 극단적으로 짧거나 긴 요약 몇 개 샘플링하여 품질/스타일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a9c9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     fname                                           dialogue  \\\n",
       " 0  train_0  #Person1#: 안녕하세요, Mr. Smith. 저는 Dr. Hawkins입니다...   \n",
       " 1  train_1  #Person1#: 안녕하세요, Mrs. Parker. 잘 지내셨나요?\\n#Pers...   \n",
       " 2  train_2  #Person1#: 저기요, 열쇠 세트 본 적 있어요?\\n#Person2#: 어떤 ...   \n",
       " 3  train_3  #Person1#: 너 여자친구 있는 거 왜 말 안 했어?\\n#Person2#: 미...   \n",
       " 4  train_4  #Person1#: 안녕, 오늘 너무 멋져 보이네요. 저랑 춤 한 곡 추실래요?\\n...   \n",
       " \n",
       "                                              summary      topic  \n",
       " 0  Mr. Smith는 Dr. Hawkins에게 건강검진을 받으러 와서, 매년 검진 필...       건강검진  \n",
       " 1  Mrs. Parker가 Ricky와 함께 백신 접종을 위해 방문하였고, Dr. Pe...      백신 접종  \n",
       " 2  #Person1#은 열쇠 세트를 잃어버리고 #Person2#에게 찾는 것을 도와달라...      열쇠 분실  \n",
       " 3  #Person1#은 #Person2#가 여자친구가 있고 결혼할 예정이라는 사실을 말...  여자친구와의 결혼  \n",
       " 4  Malik은 Wen과 Nikki에게 춤을 제안하고, Wen은 발을 밟는 것을 감수하...       춤 제안  ,\n",
       "    fname                                           dialogue  \\\n",
       " 0  dev_0  #Person1#: 안녕하세요, 오늘 기분이 어떠세요?\\n#Person2#: 요즘 ...   \n",
       " 1  dev_1  #Person1#: 야 Jimmy, 오늘 좀 이따 운동하러 가자.\\n#Person2...   \n",
       " 2  dev_2  #Person1#: 나 진짜 건강에 안 좋은 음식 좀 그만 먹어야겠어. \\n#Per...   \n",
       " 3  dev_3  #Person1#: 너 UFO 믿어?\\n#Person2#: 당연하지, 있는 거 아냐...   \n",
       " 4  dev_4  #Person1#: 오늘 학교 갔어?\\n#Person2#: 당연히 갔지. 너는?\\n...   \n",
       " \n",
       "                                              summary      topic  \n",
       " 0  #Person2#는 숨쉬기 어려워합니다. 의사는 #Person2#에게 증상을 확인하...      의사 상담  \n",
       " 1   #Person1#는 Jimmy를 운동하러 초대하고 팔과 복근 운동을 하도록 설득합니다.      운동 계획  \n",
       " 2  #Person1#은 건강에 안 좋은 음식을 그만 먹기로 결심하고, #Person2#...     건강한 식단  \n",
       " 3  #Person2#는 UFO를 믿고 꿈에서 볼 수 있다고 한다. #Person1#은 ...   UFO와 외계인  \n",
       " 4  #Person1#은 오늘 학교에 가지 않았고, #Person2#는 내일 학교 대신 ...  학교와 주말 계획  ,\n",
       "     fname                                           dialogue\n",
       " 0  test_0  #Person1#: Ms. Dawson, 받아쓰기 좀 부탁드려야겠어요. \\n#Per...\n",
       " 1  test_1  #Person1#: 드디어 왔네! 뭐가 이렇게 오래 걸렸어?\\n#Person2#: ...\n",
       " 2  test_2  #Person1#: Kate, 여기서 일어난 일을 믿기 힘들 거야.\\n#Person...\n",
       " 3  test_3  #Person1#: 생일 축하해, 이거 너를 위한 선물이야, Brian.\\n#Per...\n",
       " 4  test_4  #Person1#: 이 올림픽 공원 정말 크다! \\n#Person2#: 맞아. 지금...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로딩 셀입니다.\n",
    "# - notebooks/ 폴더에서 실행해도 항상 프로젝트 루트의 data/를 바라보도록 경로를 처리합니다.\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 이 노트북이 있는 위치 기준으로 프로젝트 루트 추정\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent  # nlp_contest/\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "DEV_PATH = DATA_DIR / \"dev.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test.csv\"\n",
    "\n",
    "missing = [p for p in [TRAIN_PATH, DEV_PATH, TEST_PATH] if not p.exists()]\n",
    "if missing:\n",
    "    missing_str = \", \".join(str(p) for p in missing)\n",
    "    raise FileNotFoundError(\n",
    "        f\"다음 파일을 찾을 수 없습니다: {missing_str}\\n\"\n",
    "        \"- 프로젝트 루트(nlp_contest) 아래 data/에 csv를 넣은 뒤 이 셀을 다시 실행하세요.\"\n",
    "    )\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "dev_df = pd.read_csv(DEV_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "train_df.head(), dev_df.head(), test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfb402",
   "metadata": {},
   "source": [
    "## 2. 데이터 구조 및 기본 통계\n",
    "\n",
    "- 각 split의 행 개수, 컬럼, 결측치, topic 유무 등 기본 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c68835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (12457, 4)\n",
      "Dev shape: (499, 4)\n",
      "Test shape: (499, 2)\n",
      "\n",
      "Train columns: ['fname', 'dialogue', 'summary', 'topic']\n",
      "Dev columns: ['fname', 'dialogue', 'summary', 'topic']\n",
      "Test columns: ['fname', 'dialogue']\n",
      "\n",
      "Train topic value_counts:\n",
      " topic\n",
      "음식 주문     130\n",
      "취업 면접     109\n",
      "길 안내       66\n",
      "호텔 체크인     40\n",
      "아파트 임대     30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dev topic value_counts:\n",
      " topic\n",
      "호텔 방 예약    5\n",
      "길 안내       4\n",
      "취업 면접      4\n",
      "음식 주문      4\n",
      "신발 구매      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Dev shape:\", dev_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "print(\"\\nTrain columns:\", train_df.columns.tolist())\n",
    "print(\"Dev columns:\", dev_df.columns.tolist())\n",
    "print(\"Test columns:\", test_df.columns.tolist())\n",
    "\n",
    "print(\"\\nTrain topic value_counts:\\n\", train_df.get(\"topic\", pd.Series()).value_counts().head())\n",
    "print(\"\\nDev topic value_counts:\\n\", dev_df.get(\"topic\", pd.Series()).value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006945d1",
   "metadata": {},
   "source": [
    "## 3. 길이 분포 분석 (문자 기준)\n",
    "\n",
    "- dialogue 길이, summary 길이의 기본 통계를 보고, encoder/decoder max length 설정이 적절한지 감각을 잡습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9629d0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== TRAIN ====\n",
      "dialogue_len_char describe:\n",
      " count    12457.000000\n",
      "mean       406.083487\n",
      "std        197.566083\n",
      "min         84.000000\n",
      "25%        280.000000\n",
      "50%        369.000000\n",
      "75%        500.000000\n",
      "max       2165.000000\n",
      "Name: dialogue_len_char, dtype: float64\n",
      "summary_len_char describe:\n",
      " count    12457.000000\n",
      "mean        85.789436\n",
      "std         33.811948\n",
      "min         13.000000\n",
      "25%         61.000000\n",
      "50%         80.000000\n",
      "75%        104.000000\n",
      "max        376.000000\n",
      "Name: summary_len_char, dtype: float64\n",
      "\n",
      "==== DEV ====\n",
      "dialogue_len_char describe:\n",
      " count     499.000000\n",
      "mean      400.054108\n",
      "std       186.163807\n",
      "min       114.000000\n",
      "25%       273.000000\n",
      "50%       367.000000\n",
      "75%       487.000000\n",
      "max      1269.000000\n",
      "Name: dialogue_len_char, dtype: float64\n",
      "summary_len_char describe:\n",
      " count    499.000000\n",
      "mean      81.206413\n",
      "std       32.577548\n",
      "min       29.000000\n",
      "25%       58.000000\n",
      "50%       74.000000\n",
      "75%       96.000000\n",
      "max      283.000000\n",
      "Name: summary_len_char, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split_name, df in [(\"train\", train_df), (\"dev\", dev_df)]:\n",
    "    df[\"dialogue_len_char\"] = df[\"dialogue\"].astype(str).str.len()\n",
    "    df[\"summary_len_char\"] = df.get(\"summary\", \"\").astype(str).str.len()\n",
    "\n",
    "    print(f\"==== {split_name.upper()} ====\")\n",
    "    print(\"dialogue_len_char describe:\\n\", df[\"dialogue_len_char\"].describe())\n",
    "    print(\"summary_len_char describe:\\n\", df[\"summary_len_char\"].describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719aa21",
   "metadata": {},
   "source": [
    "## 4. 발화(turn) 수 분포\n",
    "\n",
    "- `#Person1#`, `#Person2#` 패턴을 이용해 대화 turn 수 분포를 대략적으로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e20bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train num_turns describe:\n",
      " count    12457.000000\n",
      "mean         9.491451\n",
      "std          4.146670\n",
      "min          2.000000\n",
      "25%          7.000000\n",
      "50%          9.000000\n",
      "75%         12.000000\n",
      "max         59.000000\n",
      "Name: num_turns, dtype: float64\n",
      "Dev num_turns describe:\n",
      " count    499.000000\n",
      "mean       9.398798\n",
      "std        4.010438\n",
      "min        2.000000\n",
      "25%        6.000000\n",
      "50%        9.000000\n",
      "75%       12.000000\n",
      "max       29.000000\n",
      "Name: num_turns, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_turns(text: str) -> int:\n",
    "    return len(re.findall(r\"#Person[0-9]+#\", str(text)))\n",
    "\n",
    "train_df[\"num_turns\"] = train_df[\"dialogue\"].apply(count_turns)\n",
    "dev_df[\"num_turns\"] = dev_df[\"dialogue\"].apply(count_turns)\n",
    "\n",
    "print(\"Train num_turns describe:\\n\", train_df[\"num_turns\"].describe())\n",
    "print(\"Dev num_turns describe:\\n\", dev_df[\"num_turns\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a28a6a",
   "metadata": {},
   "source": [
    "## 5. topic별 길이/스타일 차이 (추후 확장)\n",
    "\n",
    "- topic이 존재한다면, topic별로 길이/turn 수/요약 길이 차이를 비교합니다.\n",
    "- 필요 시 시각화(히스토그램, 박스플롯)를 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "152a0818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic별로 대화 길이 / 요약 길이 / 턴 수 통계를 보는 셀입니다.\n",
    "# pandas 최신 버전에서는 여러 컬럼을 선택할 때 리스트로 넘겨야 하므로,\n",
    "# [\"col1\", \"col2\", ...] 형태로 명시적으로 지정합니다.\n",
    "if \"topic\" in train_df.columns:\n",
    "    cols = [\"dialogue_len_char\", \"summary_len_char\", \"num_turns\"]\n",
    "    topic_stats = train_df.groupby(\"topic\")[cols].describe()\n",
    "    topic_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 샘플 대화-요약 페어 확인\n",
    "\n",
    "- 무작위로 몇 개를 뽑아서, 요약 스타일과 프롬프트 설계 방향을 눈으로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== SAMPLE ====\n",
      "\n",
      "fname: train_396\n",
      "topic: 저녁 초대\n",
      "[DIALOGUE]\n",
      " #Person1#: 안녕하세요, 잭 있나요?\n",
      "#Person2#: 전데요.\n",
      "#Person1#: 잭! 나 로즈야.\n",
      "#Person2#: 안녕, 로즈. 어떻게 지내?\n",
      "#Person1#: 잘 지내, 고마워. 이번 주 토요일 저녁에 친구들 몇 명 초대했어. 너도 같이 올 수 있는지 궁금해서.\n",
      "#Person2#: 좋네. 몇 시에 가면 될까?\n",
      "#Person1#: 여섯 시 괜찮아?\n",
      "\n",
      "[SUMMARY]\n",
      " 로즈는 잭에게 전화하여 이번 주 토요일 저녁 식사에 초대한다.\n",
      "\n",
      "\n",
      "\n",
      "==== SAMPLE ====\n",
      "\n",
      "fname: train_247\n",
      "topic: 면접 준비\n",
      "[DIALOGUE]\n",
      " #Person1#: 저기요, 면접 보러 갈 때 뭐 입어야 할까요?\n",
      "#Person2#: 정장에 넥타이를 매는 게 좋을 것 같아요.\n",
      "#Person1#: 면접 중에 긴장할까 봐 걱정이에요.\n",
      "#Person2#: 걱정 마세요. 그냥 최선을 다해서 자신을 잘 표현하세요.\n",
      "\n",
      "[SUMMARY]\n",
      " #Person2#는 #Person1#에게 면접에서 정장과 넥타이를 착용하고 자신을 잘 표현하라고 조언합니다.\n",
      "\n",
      "\n",
      "\n",
      "==== SAMPLE ====\n",
      "\n",
      "fname: train_9260\n",
      "topic: 사업 전략 인터뷰\n",
      "[DIALOGUE]\n",
      " #Person1#: 존, 동기부여에 대해 몇 가지 질문이 있어요. 당신이 지역 사람들과 함께 사업을 시작한 이유가 뭔가요?\n",
      "#Person2#: 음, 저는 항상 지역 산업을 돕기 위해 지역 사람들을 고용하려고 했어요. 하지만 이 지역은 스페인의 일부 지방처럼 실업률이 낮지 않아서, 지역 외부 사람들도 고용해야 해요.\n",
      "#Person1#: 관리 스타일은 어떠세요? 존, 엄격한 관리자이신가요?\n",
      "#Person2#: 아니요, 그렇게 생각하지 않아요. 저는 강한 성격을 가졌고, 관리자로서도 강한 편이긴 하지만, 사람들을 해고해야 할 때는 다섯 번, 열 번 더 기회를 주곤 해요.\n",
      "#Person1#: 앞으로의 계획은 무엇인가요? 무엇이 계속 당신을 움직이게 하나요?\n",
      "#Person2#: 사업적으로는, 두 주 전에 새 부사장이 회사에 합류했기 때문에 이제 고객과 신제품에 더 많은 시간을 쏟을 수 있을 것 같아요. 개인적으로는 삶의 질을 개선하기로 결심했고, 매주 수요일 오후에는 휴식을 취할까 해요. 이렇게 하면 교육 과정이나 더 여유로운 활동을 할 수 있을 것 같아요.\n",
      "\n",
      "[SUMMARY]\n",
      " John은 지역 사람들과의 사업 시작 이유, 관리 스타일, 향후 사업 및 개인 생활 계획에 관해 설명합니다.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_N = 3\n",
    "sample_rows = train_df.sample(SAMPLE_N, random_state=42)\n",
    "for i, row in sample_rows.iterrows():\n",
    "    print(\"==== SAMPLE ====\\n\")\n",
    "    print(\"fname:\", row.get(\"fname\"))\n",
    "    print(\"topic:\", row.get(\"topic\"))\n",
    "    print(\"[DIALOGUE]\\n\", row[\"dialogue\"][:1000])\n",
    "    print(\"\\n[SUMMARY]\\n\", row[\"summary\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. KoBART 토크나이저 기준 토큰 길이 분포\n",
    "\n",
    "- 이 셀에서는 **KoBART 토크나이저**로 대화문을 토크나이즈했을 때 토큰 길이 분포를 봅니다.\n",
    "- encoder_max_len=1024 설정이 얼마나 여유 있는지, 잘리는 샘플 비율이 어느 정도인지 확인하는 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] dialogue_len_tok describe:\n",
      " count    12457.000000\n",
      "mean       199.561532\n",
      "std         93.123736\n",
      "min         42.000000\n",
      "25%        141.000000\n",
      "50%        183.000000\n",
      "75%        245.000000\n",
      "max       1079.000000\n",
      "Name: dialogue_len_tok, dtype: float64\n",
      "[DEV] dialogue_len_tok describe:\n",
      " count    499.000000\n",
      "mean     196.547094\n",
      "std       87.909245\n",
      "min       54.000000\n",
      "25%      139.000000\n",
      "50%      179.000000\n",
      "75%      242.500000\n",
      "max      670.000000\n",
      "Name: dialogue_len_tok, dtype: float64\n",
      "\n",
      "[TRAIN] encoder_max_len=1024 초과 비율: 0.00024082844986754435\n",
      "[DEV] encoder_max_len=1024 초과 비율: 0.0\n"
     ]
    }
   ],
   "source": [
    "# KoBART 토크나이저를 불러와서, 대화문의 토큰 길이 분포를 확인하는 셀입니다.\n",
    "# - encoder_max_len=1024 설정으로 충분한지 확인하기 위함입니다.\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "kobart_tok = PreTrainedTokenizerFast.from_pretrained(\"gogamza/kobart-base-v1\")\n",
    "\n",
    "def token_len(text: str) -> int:\n",
    "    return len(kobart_tok.encode(str(text), add_special_tokens=True))\n",
    "\n",
    "train_df[\"dialogue_len_tok\"] = train_df[\"dialogue\"].apply(token_len)\n",
    "dev_df[\"dialogue_len_tok\"] = dev_df[\"dialogue\"].apply(token_len)\n",
    "\n",
    "print(\"[TRAIN] dialogue_len_tok describe:\\n\", train_df[\"dialogue_len_tok\"].describe())\n",
    "print(\"[DEV] dialogue_len_tok describe:\\n\", dev_df[\"dialogue_len_tok\"].describe())\n",
    "print(\"\\n[TRAIN] encoder_max_len=1024 초과 비율:\", (train_df[\"dialogue_len_tok\"] > 1024).mean())\n",
    "print(\"[DEV] encoder_max_len=1024 초과 비율:\", (dev_df[\"dialogue_len_tok\"] > 1024).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 요약 길이 vs 대화 길이 상관 관계\n",
    "\n",
    "- 이 셀에서는 **대화 길이(문자 기준)**와 **요약 길이(문자 기준)**의 상관 관계를 계산합니다.\n",
    "- \"대화가 길어질수록 요약도 길어지는지\" 대략적인 경향을 보는 것이 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] dialogue_len_char vs summary_len_char 상관 계수:\n",
      "                    dialogue_len_char  summary_len_char\n",
      "dialogue_len_char           1.000000          0.716915\n",
      "summary_len_char            0.716915          1.000000\n"
     ]
    }
   ],
   "source": [
    "# 대화 길이(문자)와 요약 길이(문자)의 상관 관계를 계산하는 셀입니다.\n",
    "# - scatter plot까지는 아니지만, 상관 계수로 대략적인 경향을 봅니다.\n",
    "corr = train_df[[\"dialogue_len_char\", \"summary_len_char\"]].corr()\n",
    "print(\"[TRAIN] dialogue_len_char vs summary_len_char 상관 계수:\\n\", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 요약 스타일 키워드 빈도\n",
    "\n",
    "- 이 셀에서는 요약문에서 자주 등장하는 단어를 세어 봅니다.\n",
    "- \"환자\", \"고객\", \"상담\", \"예약\" 등 어떤 표현이 많이 나오는지 보고,\n",
    "  요약 스타일(예: 의료/상담/일상 대화 비율)을 감각적으로 파악하는 것이 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[요약문 상위 50개 토큰 빈도]\n",
      "Person1 1099\n",
      "Person2 993\n",
      "는 625\n",
      "은 539\n",
      "에게 353\n",
      "대해 212\n",
      "이 154\n",
      "의 138\n",
      "과 124\n",
      "가 117\n",
      "설명합니다 95\n",
      "합니다 93\n",
      "위해 90\n",
      "수 82\n",
      "것을 78\n",
      "있습니다 61\n",
      "말합니다 56\n",
      "함께 55\n",
      "더 54\n",
      "있다고 53\n",
      "있으며 50\n",
      "요청합니다 46\n",
      "한다 45\n",
      "Mr 45\n",
      "대한 42\n",
      "이야기합니다 42\n",
      "있는 40\n",
      "생각합니다 40\n",
      "그 37\n",
      "그들은 36\n",
      "하고 35\n",
      "자신의 32\n",
      "안내합니다 32\n",
      "제안합니다 31\n",
      "있다 31\n",
      "싶어 30\n",
      "후 30\n",
      "두 28\n",
      "것이라고 28\n",
      "말한다 27\n",
      "찾고 27\n",
      "결국 27\n",
      "이를 26\n",
      "와 26\n",
      "큰 23\n",
      "새 23\n",
      "것이 23\n",
      "그리고 23\n",
      "하며 22\n",
      "설명한다 22\n"
     ]
    }
   ],
   "source": [
    "# 요약문에서 자주 등장하는 단어의 빈도를 간단히 계산하는 셀입니다.\n",
    "# - 형태소 분석까지는 하지 않고, 한글/영문/숫자 토큰 기준으로 rough하게 봅니다.\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenize_korean(text: str):\n",
    "    return re.findall(r\"[가-힣A-Za-z0-9]+\", str(text))\n",
    "\n",
    "words = []\n",
    "sample_summaries = train_df[\"summary\"].dropna().sample(min(1000, len(train_df)), random_state=42)\n",
    "for s in sample_summaries:\n",
    "    words.extend(tokenize_korean(s))\n",
    "\n",
    "counter = Counter(words)\n",
    "print(\"[요약문 상위 50개 토큰 빈도]\")\n",
    "for w, c in counter.most_common(50):\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. train vs dev 길이 분포 비교\n",
    "\n",
    "- 이 셀에서는 train/dev 간에 **대화 길이/요약 길이 평균**이 얼마나 다른지 비교합니다.\n",
    "- train과 dev 분포가 크게 다르면, dev 성능이 실제 test 분포와도 다를 수 있으므로,\n",
    "  분포 차이를 확인하는 것이 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] dialogue_len_char mean: 406.0834871959541\n",
      "[DEV]   dialogue_len_char mean: 400.0541082164329\n",
      "[TRAIN] summary_len_char mean: 85.78943565866581\n",
      "[DEV]   summary_len_char mean: 81.2064128256513\n"
     ]
    }
   ],
   "source": [
    "# train과 dev의 길이 분포(평균 기준)를 비교하는 셀입니다.\n",
    "print(\"[TRAIN] dialogue_len_char mean:\", train_df[\"dialogue_len_char\"].mean())\n",
    "print(\"[DEV]   dialogue_len_char mean:\", dev_df[\"dialogue_len_char\"].mean())\n",
    "print(\"[TRAIN] summary_len_char mean:\", train_df[\"summary_len_char\"].mean())\n",
    "print(\"[DEV]   summary_len_char mean:\", dev_df[\"summary_len_char\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. prediction sanity check\n",
    "\n",
    "- 이 셀에서는 현재까지 생성한 **제출용 CSV**를 간단히 검증합니다.\n",
    "- 예: `fname` 중복 여부, summary가 비어 있는지, 길이 분포가 너무 극단적이지 않은지 확인합니다.\n",
    "- 아래 파일명은 예시이며, 실제로 확인하고 싶은 최신 CSV 경로로 수정해서 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일을 찾을 수 없습니다: prediction/2511292249_kobart-base-style_prompt_bs8.csv\n"
     ]
    }
   ],
   "source": [
    "# 생성된 prediction CSV가 기본 형식을 잘 따르는지 확인하는 셀입니다.\n",
    "# - fname 중복/누락, summary 공백 비율, 요약 길이 분포 등을 간단히 체크합니다.\n",
    "\n",
    "PRED_PATH = \"prediction/2511292249_kobart-base-style_prompt_bs8.csv\"  # 필요에 따라 최신 파일로 변경\n",
    "\n",
    "try:\n",
    "    pred_df = pd.read_csv(PRED_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다: {PRED_PATH}\")\n",
    "else:\n",
    "    print(pred_df.head())\n",
    "    print(\"rows:\", len(pred_df))\n",
    "    print(\"fname unique:\", pred_df[\"fname\"].nunique())\n",
    "    empty_ratio = (pred_df[\"summary\"].astype(str).str.strip() == \"\").mean()\n",
    "    print(\"empty summary 비율:\", empty_ratio)\n",
    "    print(\"summary 길이 통계:\\n\", pred_df[\"summary\"].astype(str).str.len().describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
